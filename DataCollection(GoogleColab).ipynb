{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DMzyKfC2yhtD","executionInfo":{"status":"ok","timestamp":1725892778064,"user_tz":240,"elapsed":20857,"user":{"displayName":"Haoran Li","userId":"17036897444074909179"}},"outputId":"31629003-21ea-451c-82b9-765a26a73cfe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["from collections import defaultdict\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import json\n","import pickle\n","import os\n","from pathlib import Path\n","from datetime import datetime\n","import polars as pl\n","# pl deals with parquet files efficiently\n","import gc\n","from glob import glob\n","# glob search for files more effectively\n","import lightgbm as lgb\n","import xgboost as xgb\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"PNJOyVEQyjXz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ROOT = Path(\"/content/drive/MyDrive/dataset/\")\n","TRAIN_DIR_ALL = ROOT / \"parquet_files\" / \"train\"\n","TRAIN_DIR = ROOT / \"parquet_files\" / \"selected_train\"\n","TEST_DIR  = ROOT / \"parquet_files\" / \"test\""],"metadata":{"id":"UXA_8IyLylzl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Download kaggle dataset for the first time"],"metadata":{"id":"OnIsRJt986II"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"8nQYKoLq86IJ"},"outputs":[],"source":["# Installs the Kaggle API Client\n","! pip install -q kaggle\n","\n","# Upload kaggle.json file into Files\n","# from google.colab import files\n","# files.upload()\n","\n","# Make directory named kaggle and copy kaggle.json file there\n","! mkdir ~/.kaggle\n","! cp kaggle.json ~/.kaggle/\n","\n","# Change the permissions of the file\n","! chmod 600 ~/.kaggle/kaggle.json\n","\n","# You can check if everything's okay by running this command\n","# This display all datasets available on Kaggle via the Kaggle API\n","! kaggle datasets list\n","\n","# Download competition datasets from Kaggle via the Kaggle API\n","! kaggle competitions download -c home-credit-credit-risk-model-stability\n","! mkdir ~/.kaggle/dataset\n","! unzip home-credit-credit-risk-model-stability -d ~/.kaggle/dataset"]},{"cell_type":"code","source":["# Copy the dataset into MyDrive in Google Drive\n","!cp -r /root/.kaggle/kaggle.json /content/drive/MyDrive\n","!cp -r /root/.kaggle/dataset /content/drive/MyDrive"],"metadata":{"id":"bEIiu5RW86IJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Data is too big, we randomly select some data"],"metadata":{"id":"VnypyDAI-BHm"}},{"cell_type":"code","source":["import random\n","\n","# Define the range, subset size, and random seed\n","total_range = 3000000\n","subset_size = 100000\n","\n","# Set the random seed\n","random.seed(42)\n","\n","# Generate a random subset of the specified size\n","subset = random.sample(range(1, total_range + 1), subset_size)\n","\n","# Get all test ids\n","test_ids = set()\n","for filename in os.listdir(ROOT / \"parquet_files\" / \"test\"):\n","    df = pl.read_parquet(ROOT / \"parquet_files\" / \"test\" / filename)\n","    test_ids |= set(df['case_id'])\n","test_ids\n","\n","# Union to form the selected ids\n","selected_ids = set(subset) | test_ids"],"metadata":{"id":"KXvpU3EL-BHn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.listdir(TRAIN_DIR_ALL)"],"metadata":{"id":"O2IuaUtj-BHn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["filename = \"train_base.parquet\"\n","df = pl.read_parquet(TRAIN_DIR_ALL / filename)\n","df = df.filter(pl.col('case_id').is_in(selected_ids))"],"metadata":{"id":"J1L6Fjt--BHn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.write_parquet(TRAIN_DIR / filename)\n","pl.read_parquet(TRAIN_DIR / filename)"],"metadata":{"id":"8gfQJFpP-BHn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# multiple storage for \"train_credit_bureau_a_2_5.parquet\" since it is an unusually large file\n","\n","'''\n","col_name = pl.read_csv(ROOT / \"csv_files/train\" / \"train_credit_bureau_a_2_5.csv\", n_rows=10000000).columns\n","df = pl.read_csv(ROOT / \"csv_files/train\" / \"train_credit_bureau_a_2_5.csv\", skip_rows=30000000, n_rows=10000000)\n","df.columns = col_name\n","df = df.filter(pl.col('case_id').is_in(selected_ids))\n","df.write_parquet(ROOT / \"parquet_files/selected_train\" / \"train_credit_bureau_a_2_5_3.parquet\")\n","pl.read_parquet(ROOT / \"parquet_files/selected_train\" / \"train_credit_bureau_a_2_5_3.parquet\")\n","'''"],"metadata":{"id":"9i8ylqp7-BHn"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOtoQ6qVX+At9Th9w8E6S8I"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}